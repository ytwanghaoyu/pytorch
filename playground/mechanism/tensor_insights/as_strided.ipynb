{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41a062b8",
   "metadata": {},
   "source": [
    "## 导入必要的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4279cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa078d39",
   "metadata": {},
   "source": [
    "## 实战案例一：手动提取矩阵对角线\n",
    "\n",
    "假设有一个 $3 \\times 3$ 的矩阵，我们要提取它的对角线元素 [0, 4, 8]。常规方法可能是 `torch.diagonal`，但我们看看 `as_strided` 怎么做。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a849b749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始矩阵:\n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]])\n"
     ]
    }
   ],
   "source": [
    "# 1. 创建 3x3 矩阵\n",
    "A = torch.arange(9).view(3, 3)\n",
    "print(f\"原始矩阵:\\n{A}\")\n",
    "# 0 1 2\n",
    "# 3 4 5\n",
    "# 6 7 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fa4730",
   "metadata": {},
   "source": [
    "### 分析内存布局\n",
    "\n",
    "- 内存里是: [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
    "- A 的 stride 是 (3, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d524205",
   "metadata": {},
   "source": [
    "### 计算对角线的 Stride\n",
    "\n",
    "- 对角线是: A[0,0] -> 0, A[1,1] -> 4, A[2,2] -> 8\n",
    "- 观察物理内存索引: 0 -> 4 -> 8\n",
    "- 每次跳跃距离 = 4 个元素\n",
    "- 为什么是 4? 因为换一行要跳 3 (stride[0])，换一列要跳 1 (stride[1])。 3 + 1 = 4。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbeeac39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "提取的对角线: tensor([0, 4, 8])\n"
     ]
    }
   ],
   "source": [
    "# 施法：提取对角线\n",
    "diagonal = torch.as_strided(\n",
    "    A,\n",
    "    size=(3,),  # 只要 3 个元素\n",
    "    stride=(4,),  # 每次跳 4 步\n",
    ")\n",
    "\n",
    "print(f\"\\n提取的对角线: {diagonal}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47408c86",
   "metadata": {},
   "source": [
    "### 验证零拷贝特性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81cd32e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "修改对角线第一个元素...\n",
      "查看原矩阵(零拷贝证明):\n",
      "tensor([[999,   1,   2],\n",
      "        [  3,   4,   5],\n",
      "        [  6,   7,   8]])\n"
     ]
    }
   ],
   "source": [
    "print(\"修改对角线第一个元素...\")\n",
    "diagonal[0] = 999\n",
    "print(f\"查看原矩阵(零拷贝证明):\\n{A}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92e2108",
   "metadata": {},
   "source": [
    "## 实战案例二：滑窗操作 (Sliding Window)\n",
    "\n",
    "这是 `as_strided` 最著名的用法。假设有一个序列 [0, 1, 2, 3, 4]，我们想要做一个窗口大小为 3 的滑窗：\n",
    "\n",
    "- 窗口1: [0, 1, 2]\n",
    "- 窗口2: [1, 2, 3]\n",
    "- 窗口3: [2, 3, 4]\n",
    "\n",
    "思考：这看似复制了数据，实际上可以零拷贝实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c36c01fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 原始序列\n",
    "x = torch.arange(5)  # [0, 1, 2, 3, 4]\n",
    "# stride: (1,) -> 动一步跳1个元素\n",
    "\n",
    "# 2. 目标形状\n",
    "# 我们想要 3 个窗口，每个窗口长 3\n",
    "target_size = (3, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fd9694",
   "metadata": {},
   "source": [
    "### 计算神奇的 Stride\n",
    "\n",
    "- 第0维(窗口维): 从 \"窗口1\" 到 \"窗口2\" (即从 0 到 1)。内存跳几步？ -> 跳 1 步。\n",
    "- 第1维(窗内维): 从 \"窗口内的0\" 到 \"窗口内的1\" (即从 0 到 1)。内存跳几步？ -> 也是跳 1 步！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c067f3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始数据: tensor([0, 1, 2, 3, 4])\n",
      "滑窗视图:\n",
      "tensor([[0, 1, 2],\n",
      "        [1, 2, 3],\n",
      "        [2, 3, 4]])\n"
     ]
    }
   ],
   "source": [
    "target_stride = (1, 1)\n",
    "\n",
    "# 施法\n",
    "windows = torch.as_strided(x, size=target_size, stride=target_stride)\n",
    "\n",
    "print(f\"原始数据: {x}\")\n",
    "print(f\"滑窗视图:\\n{windows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bc60d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "内存地址是否相同: True\n"
     ]
    }
   ],
   "source": [
    "# 验证是否真的没复制\n",
    "print(f\"\\n内存地址是否相同: {x.data_ptr() == windows.data_ptr()}\")\n",
    "# 看起来好像多了很多数据，其实只是同一段内存在被反复读取"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af302859",
   "metadata": {},
   "source": [
    "## 实战案例三：Unfold + im2col\n",
    "\n",
    "我们要构造一个 4 维张量，形状为 (输出行, 输出列, 核高, 核宽)，即 (3, 3, 2, 2)。\n",
    "\n",
    "### 思考 Stride 的设计\n",
    "\n",
    "- Dim 0 (窗口向下移): 图片物理内存要跳过一行，即跳 4 个元素。\n",
    "- Dim 1 (窗口向右移): 图片物理内存要跳过一列，即跳 1 个元素。\n",
    "- Dim 2 (窗口内部向下): 在窗口内部下一行，其实就是原图的下一行，跳 4 个元素。\n",
    "- Dim 3 (窗口内部向右): 在窗口内部下一列，其实就是原图的下一列，跳 1 个元素。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f452f44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始图片 (4x4):\n",
      "tensor([[ 1.,  2.,  3.,  4.],\n",
      "        [ 5.,  6.,  7.,  8.],\n",
      "        [ 9., 10., 11., 12.],\n",
      "        [13., 14., 15., 16.]])\n"
     ]
    }
   ],
   "source": [
    "# 1. 模拟一张 4x4 的图片 (H=4, W=4)\n",
    "img = torch.arange(1, 17).float().view(4, 4)\n",
    "print(f\"原始图片 (4x4):\\n{img}\")\n",
    "# Stride: (4, 1) -> 换行跳4个元素，换列跳1个元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9a62f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "# 2. 使用 as_strided 手动提取窗口\n",
    "# 目标形状: (3, 3, 2, 2) -> (Out_H, Out_W, Kernel_H, Kernel_W)\n",
    "H, W = img.shape\n",
    "KH, KW = 2, 2\n",
    "OH, OW = H - KH + 1, W - KW + 1  # 输出尺寸 3x3\n",
    "\n",
    "# 原始 stride 是 (4, 1)\n",
    "s0, s1 = img.stride()\n",
    "\n",
    "# 构造 Magic Stride\n",
    "# 关键点：Dim 0 和 Dim 2 的 stride 是一样的！Dim 1 和 Dim 3 的 stride 是一样的！\n",
    "windows = torch.as_strided(\n",
    "    img,\n",
    "    size=(OH, OW, KH, KW),\n",
    "    stride=(s0, s1, s0, s1),  # (4, 1, 4, 1)\n",
    ")\n",
    "print(windows.shape)  # 应该是 (3, 3, 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8182ffab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "as_strided 提取的窗口视图 (3, 3, 2, 2):\n",
      "tensor([[1., 2.],\n",
      "        [5., 6.]])\n",
      "tensor([[2., 3.],\n",
      "        [6., 7.]])\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nas_strided 提取的窗口视图 (3, 3, 2, 2):\")\n",
    "print(windows[0, 0])  # 打印第一个窗口 (左上角)\n",
    "print(windows[0, 1])  # 打印第二个窗口 (向右滑一步)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3365b4bc",
   "metadata": {},
   "source": [
    "### 拉直每个窗口 -> 变成 (9, 4) 矩阵\n",
    "\n",
    "9 个窗口，每个窗口 4 个像素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f62bb3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "手动实现的 im2col 矩阵 (4, 9):\n",
      "tensor([[ 1.,  2.,  3.,  5.,  6.,  7.,  9., 10., 11.],\n",
      "        [ 2.,  3.,  4.,  6.,  7.,  8., 10., 11., 12.],\n",
      "        [ 5.,  6.,  7.,  9., 10., 11., 13., 14., 15.],\n",
      "        [ 6.,  7.,  8., 10., 11., 12., 14., 15., 16.]])\n"
     ]
    }
   ],
   "source": [
    "# .t() 是为了适应 PyTorch unfold 的格式 (C*K*K, L)\n",
    "# 注意：这里调用 contiguous() 会触发复制，因为 view 需要连续内存。\n",
    "# 但在底层 GEMM 优化中，往往直接对 strided 内存操作或分块复制。\n",
    "\n",
    "im2col_manual = windows.contiguous().view(-1, KH * KW).t()\n",
    "\n",
    "print(f\"\\n手动实现的 im2col 矩阵 (4, 9):\\n{im2col_manual}\")\n",
    "# 每一列代表一个 2x2 的窗口的数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c949bc02",
   "metadata": {},
   "source": [
    "### 使用官方 API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f1d8288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "官方 F.unfold 输出 (1, 4, 9):\n",
      "tensor([[[ 1.,  2.,  3.,  5.,  6.,  7.,  9., 10., 11.],\n",
      "         [ 2.,  3.,  4.,  6.,  7.,  8., 10., 11., 12.],\n",
      "         [ 5.,  6.,  7.,  9., 10., 11., 13., 14., 15.],\n",
      "         [ 6.,  7.,  8., 10., 11., 12., 14., 15., 16.]]])\n",
      "两者是否一致: True\n"
     ]
    }
   ],
   "source": [
    "# unfold 输入必须是 4 维 (N, C, H, W)\n",
    "input_tensor = img.view(1, 1, 4, 4)\n",
    "\n",
    "# kernel_size=2\n",
    "unfold_out = F.unfold(input_tensor, kernel_size=2)\n",
    "\n",
    "print(f\"\\n官方 F.unfold 输出 (1, 4, 9):\\n{unfold_out}\")\n",
    "print(f\"两者是否一致: {torch.allclose(im2col_manual, unfold_out[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7065a39",
   "metadata": {},
   "source": [
    "### 执行卷积 = 矩阵乘法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ab8b74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "卷积结果:\n",
      "tensor([[14., 18., 22.],\n",
      "        [30., 34., 38.],\n",
      "        [46., 50., 54.]])\n"
     ]
    }
   ],
   "source": [
    "# 卷积核\n",
    "kernel = torch.tensor([[1.0, 1.0], [1.0, 1.0]]).view(1, 4)  # 拉直成 1行4列\n",
    "\n",
    "# 执行卷积 = 矩阵乘法\n",
    "# (1, 4) x (4, 9) = (1, 9)\n",
    "conv_res = kernel @ unfold_out[0]\n",
    "\n",
    "# 变回图片形状 (3, 3)\n",
    "output_img = conv_res.view(3, 3)\n",
    "\n",
    "print(f\"\\n卷积结果:\\n{output_img}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09eb55bd",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "- **as_strided 是魔术师的手法**：它通过设置重复的 stride（如 4, 1, 4, 1），让同一个物理像素在逻辑张量中出现多次（既属于窗口A，也属于窗口B），实现了零拷贝的窗口切分。\n",
    "\n",
    "- **Unfold 是魔术的包装**：它封装了 stride 计算和 reshape 操作，直接输出 im2col 格式的矩阵（Columns）。\n",
    "\n",
    "- **im2col 是最终效果**：通过上述操作，将复杂的卷积变成了简单的矩阵乘法（Kernel_Matrix @ Unfolded_Image），从而利用 GPU 强大的 Tensor Core 进行并行计算。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
