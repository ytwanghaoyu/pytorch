{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8a4fc54",
   "metadata": {},
   "source": [
    "## 导入必要的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f13b7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79428eba",
   "metadata": {},
   "source": [
    "## 定义自定义算子 Schema\n",
    "\n",
    "这里的 `'my_ops::custom_add'` 就是我们在 OperatorHandle 中查找的名字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ebe0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.library.define(\"my_ops::custom_add\", \"(Tensor x, Tensor y) -> Tensor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e548c9",
   "metadata": {},
   "source": [
    "## 注册 CPU 后端的实现\n",
    "\n",
    "对应 M x N 中的 N=CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052a3a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.library.impl(\"my_ops::custom_add\", \"CPU\")\n",
    "def custom_add_cpu(x, y):\n",
    "    print(\"[Backend: CPU] 正在执行底层的加法计算...\")\n",
    "    return x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9ad7ba",
   "metadata": {},
   "source": [
    "## 注册 Autograd 后端的实现\n",
    "\n",
    "对应 M x N 中的 N=Autograd\n",
    "\n",
    "Autograd 层负责处理反向传播逻辑，然后 \"Redispatch\" 给底层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8274bec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.library.impl(\"my_ops::custom_add\", \"Autograd\")\n",
    "def custom_add_autograd(ctx, x, y):\n",
    "    print(\"[Backend: Autograd] 拦截到了调用！正在记录计算图...\")\n",
    "    # 在这里，PyTorch 内部会做一个 exclude(Autograd) 的操作，\n",
    "    # 然后再次调用算子，这次因为没有了 Autograd Key，就会掉落到上面的 CPU 实现中。\n",
    "    # 为了模拟这个过程，我们直接调用 torch.ops.my_ops.custom_add\n",
    "    # (注意：真实的 C++ 实现中通过 ctx.save_for_backward 等机制处理，这里是逻辑演示)\n",
    "\n",
    "    with torch._C._DisableAutograd():  # 模拟 Redispatch 时的 Key 剔除\n",
    "        result = torch.ops.my_ops.custom_add(x, y)\n",
    "\n",
    "    print(\"[Backend: Autograd] 底层计算完毕，返回结果。\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446aea17",
   "metadata": {},
   "source": [
    "## 测试代码"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5764bff7",
   "metadata": {},
   "source": [
    "### 场景 1: 普通 CPU Tensor（不求导）\n",
    "\n",
    "分发逻辑: Key(CPU) -> 匹配到 custom_add_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fe003e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- 场景 1: 普通 CPU Tensor (不求导) ---\")\n",
    "t1 = torch.ones(2)\n",
    "t2 = torch.ones(2)\n",
    "res1 = torch.ops.my_ops.custom_add(t1, t2)\n",
    "print(f\"Result: {res1}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102e7b7d",
   "metadata": {},
   "source": [
    "### 场景 2: 需要求导的 Tensor\n",
    "\n",
    "分发逻辑: \n",
    "- Key(Autograd, CPU) \n",
    "- -> 优先匹配 Autograd \n",
    "- -> custom_add_autograd\n",
    "- -> (Redispatch) \n",
    "- -> Key(CPU) \n",
    "- -> custom_add_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7e46b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- 场景 2: 需要求导的 Tensor (Requires Grad) ---\")\n",
    "t3 = torch.ones(2, requires_grad=True)\n",
    "t4 = torch.ones(2)\n",
    "res2 = torch.ops.my_ops.custom_add(t3, t4)\n",
    "print(f\"Result: {res2}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
