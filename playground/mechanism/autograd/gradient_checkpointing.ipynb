{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb359f39",
   "metadata": {},
   "source": [
    "## 导入必要的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ffbf295",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.checkpoint as checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289713cf",
   "metadata": {},
   "source": [
    "## 辅助函数\n",
    "\n",
    "定义用于监控内存使用和重置内存状态的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bf8807b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_memory_usage():\n",
    "    \"\"\"Returns current GPU memory usage in MB.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.cuda.memory_allocated() / 1024 / 1024\n",
    "    return 0\n",
    "\n",
    "def reset_memory():\n",
    "    \"\"\"Clears cache and garbage collects to ensure fair measurement.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149ae754",
   "metadata": {},
   "source": [
    "## 定义模型组件\n",
    "\n",
    "创建一个占用大量激活内存的层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b7793dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeavyLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    A layer designed to consume significant activation memory.\n",
    "    It performs a large matrix multiplication and an activation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, size=2048):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(size, size)\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.act(self.linear(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c30b6d4",
   "metadata": {},
   "source": [
    "## 支持检查点的模型\n",
    "\n",
    "定义一个可选择性使用梯度检查点的顺序模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45a7de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CheckpointedModel(nn.Module):\n",
    "    \"\"\"\n",
    "    A sequential model that can optionally use gradient checkpointing.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_layers=20, size=2048, use_checkpointing=False):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([HeavyLayer(size) for _ in range(num_layers)])\n",
    "        self.use_checkpointing = use_checkpointing\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.use_checkpointing:\n",
    "            # Apply checkpointing to chunks of layers (e.g., every 4 layers)\n",
    "            # This ensures that activations for entire segments are not stored\n",
    "            for i in range(0, len(self.layers), 4):\n",
    "                # Create a sequential block of 4 layers\n",
    "                def run_segment(x, start_idx=i):\n",
    "                    for j in range(start_idx, min(start_idx + 4, len(self.layers))):\n",
    "                        x = self.layers[j](x)\n",
    "                    return x\n",
    "\n",
    "                # Checkpoint the entire segment\n",
    "                x = checkpoint.checkpoint(run_segment, x, use_reentrant=False)\n",
    "        else:\n",
    "            # Standard forward pass - all activations are saved\n",
    "            for layer in self.layers:\n",
    "                x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe18cc6",
   "metadata": {},
   "source": [
    "## 实验函数\n",
    "\n",
    "运行实验来测量有无梯度检查点时的内存使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c40959c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(use_checkpointing: bool):\n",
    "    print(\n",
    "        f\"\\n--- Running Experiment: Checkpointing={'ON' if use_checkpointing else 'OFF'} ---\"\n",
    "    )\n",
    "    reset_memory()\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Setup model and data\n",
    "    model = CheckpointedModel(\n",
    "        num_layers=20, size=4096, use_checkpointing=use_checkpointing\n",
    "    ).to(device)\n",
    "    inputs = torch.randn(32, 4096, device=device, requires_grad=True)\n",
    "\n",
    "    # Measure memory before forward\n",
    "    mem_start = get_memory_usage()\n",
    "    print(f\"Memory Usage Before Forward: {mem_start:.2f} MB\")\n",
    "\n",
    "    # Forward pass\n",
    "    output = model(inputs)\n",
    "    loss = output.sum()\n",
    "\n",
    "    # Measure peak memory after forward (before backward)\n",
    "    assert device.type == \"cuda\"\n",
    "    mem_after_forward = torch.cuda.memory_allocated() / 1024 / 1024\n",
    "    mem_peak_forward = torch.cuda.max_memory_allocated() / 1024 / 1024\n",
    "\n",
    "    print(\"Forward pass complete.\")\n",
    "    print(f\"Memory Usage After Forward (before backward): {mem_after_forward:.2f} MB\")\n",
    "    print(f\"Peak Memory Usage During Forward: {mem_peak_forward:.2f} MB\")\n",
    "\n",
    "    # Reset peak stats to measure backward separately\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    mem_peak_backward = torch.cuda.max_memory_allocated() / 1024 / 1024\n",
    "    mem_after_backward = torch.cuda.memory_allocated() / 1024 / 1024\n",
    "\n",
    "    print(f\"Peak Memory Usage During Backward: {mem_peak_backward:.2f} MB\")\n",
    "    print(f\"Memory Usage After Backward: {mem_after_backward:.2f} MB\")\n",
    "    print(\"Backward pass complete.\")\n",
    "\n",
    "    # Calculate total peak memory (forward + backward)\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    return mem_after_forward, mem_peak_backward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26e0389",
   "metadata": {},
   "source": [
    "## 运行实验\n",
    "\n",
    "### 说明\n",
    "\n",
    "这个脚本演示了梯度检查点如何以计算换内存。它构建了一个深度网络，并测量了有无检查点时的峰值内存使用。\n",
    "\n",
    "**注意：** 这个示例在 GPU 上观看效果最佳，可以看到精确的内存分配统计。在 CPU 上运行仅用于演示逻辑。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f12e5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Gradient Checkpointing Demonstration\n",
      "============================================\n",
      "This script demonstrates how gradient checkpointing trades compute for memory.\n",
      "It constructs a deep network and measures peak memory usage with and without checkpointing.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if not torch.cuda.is_available():\n",
    "    raise RuntimeError(\"This script is best run on a machine with a CUDA-capable GPU.\")\n",
    "\n",
    "print(\"PyTorch Gradient Checkpointing Demonstration\")\n",
    "print(\"============================================\")\n",
    "print(\n",
    "    \"This script demonstrates how gradient checkpointing trades compute for memory.\"\n",
    ")\n",
    "print(\n",
    "    \"It constructs a deep network and measures peak memory usage with and without checkpointing.\\n\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c481d4fd",
   "metadata": {},
   "source": [
    "### 1. 不使用检查点运行（标准行为）\n",
    "\n",
    "这将为所有 20 层存储激活值以计算梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fac8bf8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Experiment: Checkpointing=OFF ---\n",
      "Memory Usage Before Forward: 1299.06 MB\n",
      "Forward pass complete.\n",
      "Memory Usage After Forward (before backward): 1309.06 MB\n",
      "Peak Memory Usage During Forward: 1309.56 MB\n",
      "Peak Memory Usage During Backward: 2580.88 MB\n",
      "Memory Usage After Backward: 2580.38 MB\n",
      "Backward pass complete.\n",
      "Memory Usage Before Forward: 1299.06 MB\n",
      "Forward pass complete.\n",
      "Memory Usage After Forward (before backward): 1309.06 MB\n",
      "Peak Memory Usage During Forward: 1309.56 MB\n",
      "Peak Memory Usage During Backward: 2580.88 MB\n",
      "Memory Usage After Backward: 2580.38 MB\n",
      "Backward pass complete.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1309.06298828125, 2580.8759765625)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_experiment(use_checkpointing=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a016d68a",
   "metadata": {},
   "source": [
    "### 2. 使用检查点运行\n",
    "\n",
    "这将只存储每个检查点段的输入。段内的激活值在反向传播期间重新计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2656ebc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Experiment: Checkpointing=ON ---\n",
      "Memory Usage Before Forward: 1299.06 MB\n",
      "Forward pass complete.\n",
      "Memory Usage After Forward (before backward): 1301.56 MB\n",
      "Peak Memory Usage During Forward: 1302.56 MB\n",
      "Peak Memory Usage During Backward: 2580.88 MB\n",
      "Memory Usage After Backward: 2580.38 MB\n",
      "Backward pass complete.\n",
      "Memory Usage Before Forward: 1299.06 MB\n",
      "Forward pass complete.\n",
      "Memory Usage After Forward (before backward): 1301.56 MB\n",
      "Peak Memory Usage During Forward: 1302.56 MB\n",
      "Peak Memory Usage During Backward: 2580.88 MB\n",
      "Memory Usage After Backward: 2580.38 MB\n",
      "Backward pass complete.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1301.56298828125, 2580.8759765625)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_experiment(use_checkpointing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e8bb87",
   "metadata": {},
   "source": [
    "## 结果分析\n",
    "\n",
    "从上面的结果可以看到：\n",
    "\n",
    "### Forward Pass 内存差异（关键指标）\n",
    "- **不使用检查点**: Forward 后内存 ~1309 MB\n",
    "- **使用检查点**: Forward 后内存 ~1302 MB\n",
    "\n",
    "虽然差异不是很大（约 7-8 MB），这是因为：\n",
    "\n",
    "1. **模型参数和梯度始终需要存储**（约 1.3 GB）\n",
    "2. **激活值的节省主要体现在前向传播后**\n",
    "3. **Backward 峰值相同是正常的**，因为：\n",
    "   - 梯度检查点在 backward 时需要重新计算前向传播\n",
    "   - 重新计算时仍然会临时产生激活值\n",
    "   - 参数梯度必须保存\n",
    "\n",
    "### 如何看到更明显的差异？\n",
    "\n",
    "要看到更显著的内存节省，需要：\n",
    "1. 使用更深的网络（50+ 层）\n",
    "2. 使用更大的批次大小\n",
    "3. 使用更大的隐藏层维度\n",
    "4. 关注 forward 后的内存使用，而不是 backward 峰值"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fac78a3",
   "metadata": {},
   "source": [
    "## 更极端的例子\n",
    "\n",
    "让我们用更大的模型来展示更明显的内存差异"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10aece4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_extreme_experiment(use_checkpointing: bool):\n",
    "    \"\"\"\n",
    "    使用更大的模型参数来展示更明显的内存差异\n",
    "    \"\"\"\n",
    "    print(\n",
    "        f\"\\n--- EXTREME Experiment: Checkpointing={'ON' if use_checkpointing else 'OFF'} ---\"\n",
    "    )\n",
    "    reset_memory()\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # 更大的模型：更多层，更大的尺寸，更大的批次\n",
    "    model = CheckpointedModel(\n",
    "        num_layers=40,  # 40 层\n",
    "        size=4096,      # 4096 维度\n",
    "        use_checkpointing=use_checkpointing\n",
    "    ).to(device)\n",
    "\n",
    "    # 更大的批次\n",
    "    inputs = torch.randn(64, 4096, device=device, requires_grad=True)\n",
    "\n",
    "    mem_start = get_memory_usage()\n",
    "    print(f\"Memory Before Forward: {mem_start:.2f} MB\")\n",
    "\n",
    "    # Forward\n",
    "    output = model(inputs)\n",
    "    loss = output.sum()\n",
    "\n",
    "    mem_after_forward = torch.cuda.memory_allocated() / 1024 / 1024\n",
    "    print(f\"Memory After Forward: {mem_after_forward:.2f} MB\")\n",
    "    print(f\"  → Activation Memory: {mem_after_forward - mem_start:.2f} MB\")\n",
    "\n",
    "    # Backward\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    loss.backward()\n",
    "\n",
    "    mem_peak_backward = torch.cuda.max_memory_allocated() / 1024 / 1024\n",
    "    print(f\"Peak Memory During Backward: {mem_peak_backward:.2f} MB\")\n",
    "\n",
    "    return mem_after_forward - mem_start, mem_peak_backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38e37913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "极端测试：40 层，批次大小 64\n",
      "============================================================\n",
      "\n",
      "--- EXTREME Experiment: Checkpointing=OFF ---\n",
      "Memory Before Forward: 2579.88 MB\n",
      "Memory After Forward: 2619.88 MB\n",
      "  → Activation Memory: 40.00 MB\n",
      "Peak Memory During Backward: 5143.50 MB\n",
      "\n",
      "--- EXTREME Experiment: Checkpointing=ON ---\n",
      "Memory Before Forward: 2579.88 MB\n",
      "Memory After Forward: 2589.88 MB\n",
      "  → Activation Memory: 10.00 MB\n",
      "Peak Memory During Backward: 5143.50 MB\n",
      "\n",
      "============================================================\n",
      "对比总结\n",
      "============================================================\n",
      "不使用检查点 - Forward 激活内存: 40.00 MB\n",
      "使用检查点   - Forward 激活内存: 10.00 MB\n",
      "内存节省: 30.00 MB (75.0%)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"极端测试：40 层，批次大小 64\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "result_no_ckpt = run_extreme_experiment(use_checkpointing=False)\n",
    "result_with_ckpt = run_extreme_experiment(use_checkpointing=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"对比总结\")\n",
    "print(\"=\"*60)\n",
    "print(f\"不使用检查点 - Forward 激活内存: {result_no_ckpt[0]:.2f} MB\")\n",
    "print(f\"使用检查点   - Forward 激活内存: {result_with_ckpt[0]:.2f} MB\")\n",
    "print(f\"内存节省: {result_no_ckpt[0] - result_with_ckpt[0]:.2f} MB ({(1 - result_with_ckpt[0]/result_no_ckpt[0])*100:.1f}%)\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
