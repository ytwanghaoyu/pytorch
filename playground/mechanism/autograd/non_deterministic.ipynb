{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe97518c",
   "metadata": {},
   "source": [
    "## 导入必要的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e87defd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c684e7b9",
   "metadata": {},
   "source": [
    "## 浮点数加法的非结合性\n",
    "\n",
    "模拟在多线程环境下，梯度累加顺序不同导致的微小差异\n",
    "\n",
    "### \"大数吃小数\" 现象\n",
    "\n",
    "`(A + small) + small` vs `A + (small + small)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b968a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov 30 03:47:26 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   54C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c232c54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum A: 100000000.00000000000000000000\n",
      "Sum B: 100000000.00000000000000000000\n",
      "Difference exists: False\n"
     ]
    }
   ],
   "source": [
    "large_grad = torch.tensor([1e8], dtype=torch.float32).cuda()\n",
    "small_grad = torch.tensor([1e-5], dtype=torch.float32).cuda()\n",
    "\n",
    "# 顺序 A: 先加两个小的，再加大数 (模拟线程 1, 2 先完成，3 后完成)\n",
    "sum_a = (small_grad + small_grad) + large_grad\n",
    "\n",
    "# 顺序 B: 大数先加小数，再加小数 (模拟线程 3 先完成，1, 2 陆续完成)\n",
    "sum_b = (large_grad + small_grad) + small_grad\n",
    "\n",
    "diff = sum_a - sum_b\n",
    "print(f\"Sum A: {sum_a.item():.20f}\")\n",
    "print(f\"Sum B: {sum_b.item():.20f}\")\n",
    "print(f\"Difference exists: {diff.item() != 0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b630f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum A (small first): 16777216.0\n",
      "Sum B (large first): 16777216.0\n",
      "Difference: 0.0\n"
     ]
    }
   ],
   "source": [
    "# 重新设定数值，利用 float32 在 2^24 (16777216) 处分辨率为 1.0 的特性\n",
    "large_grad = torch.tensor([16777216.0], dtype=torch.float32).cuda()\n",
    "small_grad = torch.tensor([0.4], dtype=torch.float32).cuda()\n",
    "\n",
    "# 顺序 A: 先累加小数，积少成多，足以影响大数\n",
    "# 0.4 + 0.4 = 0.8\n",
    "# 16777216.0 + 0.8 -> 16777217.0 (因为 0.8 > 0.5，进位)\n",
    "sum_a = large_grad + (small_grad + small_grad)\n",
    "\n",
    "# 顺序 B: 大数直接吃掉小数\n",
    "# 16777216.0 + 0.4 -> 16777216.0 (因为 0.4 < 0.5，被舍弃)\n",
    "# 16777216.0 + 0.4 -> 16777216.0 (再次被舍弃)\n",
    "sum_b = (large_grad + small_grad) + small_grad\n",
    "\n",
    "diff = sum_a - sum_b\n",
    "print(f\"Sum A (small first): {sum_a.item():.1f}\")\n",
    "print(f\"Sum B (large first): {sum_b.item():.1f}\")\n",
    "print(f\"Difference: {diff.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3a6386",
   "metadata": {},
   "source": [
    "## 理论背景\n",
    "\n",
    "虽然很难在 Python 简单脚本中稳定复现多线程竞态导致的数值差异（因为现代 CPU/GPU 极快且 Python 有 GIL），但我们可以从数学原理上演示为什么\"加法顺序\"会导致结果不同，这是 Autograd 多线程非确定性的根源。\n",
    "\n",
    "### Autograd 引擎的多线程特性\n",
    "\n",
    "Autograd 引擎在 C++ 层是多线程执行的（例如 Hogwild 模式或并行分支）。多个线程可能几乎同时尝试把梯度加到同一个叶子节点的 `.grad` 上。虽然 AccumulateGrad 有锁（Mutex）保证不会崩溃，但谁先抢到锁是不确定的。\n",
    "\n",
    "### 浮点数精度限制\n",
    "\n",
    "代码展示了即使是简单的加法，由于浮点数精度限制（Float32），`(a+b)+c` 并不总是等于 `a+(b+c)`。在深度学习数百万次迭代中，这种微小的\"非确定性\"是客观存在的。这也是为什么完全复现某些训练结果非常困难的原因之一。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
